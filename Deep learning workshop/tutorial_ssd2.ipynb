{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning implementation\n",
    "\n",
    "Single Shot Detector based Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet\n",
    "!wget -P checkpoints https://github.com/500swapnil/Keras_Efficientnet_SSD/releases/download/v1.0/efficientnetb0_SSD.h5\n",
    "!wget -P checkpoints https://github.com/500swapnil/Keras_Efficientnet_SSD/releases/download/v1.0/efficientnetb5_SSD.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Shot Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load python packet   \n",
    "# ----------------------start--------------------------------\n",
    "# load necessary packets\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import tensorflow as tf\n",
    "\n",
    "# load utilities\n",
    "from utils.priors import *\n",
    "from model.ssd import ssd\n",
    "from utils.post_processing import post_process\n",
    "from utils.preprocessing import prepare_for_prediction\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters & directory paths\n",
    "# ----------------------start--------------------------------\n",
    "# define parameter\n",
    "IMAGE_SIZE = [300, 300]\n",
    "# define parameter\n",
    "BATCH_SIZE = 16\n",
    "# choose backbone net [B0, B1, B2, ..., B7]\n",
    "MODEL_NAME = 'B0'\n",
    "\n",
    "# directory path of weight of pretrained model [./checkpoints/efficientnetb0_SSD.h5]\n",
    "checkpoint_filepath = ??? \n",
    "# directory path of input image\n",
    "INPUT_DIR = './images'\n",
    "# directory path of output image\n",
    "OUTPUT_DIR = './outputs'\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters of SSD\n",
    "# ----------------------start--------------------------------\n",
    "# set positive box's threshold\n",
    "iou_threshold = 0.5\n",
    "# set anchor center's variance\n",
    "center_variance = 0.1\n",
    "# set anchor size's variance\n",
    "size_variance = 0.2\n",
    "\n",
    "# set anchor boxes\n",
    "specs = [\n",
    "                SSDSpec(38, 8, SSDBoxSizes(30, 60), [2]),\n",
    "                SSDSpec(19, 16, SSDBoxSizes(60, 111), [2, 3]),\n",
    "                SSDSpec(10, 32, SSDBoxSizes(111, 162), [2, 3]),\n",
    "                SSDSpec(5, 64, SSDBoxSizes(162, 213), [2, 3]),\n",
    "                SSDSpec(3, 100, SSDBoxSizes(213, 264), [2]),\n",
    "                SSDSpec(1, 300, SSDBoxSizes(264, 315), [2])\n",
    "        ]\n",
    "\n",
    "# create SSD's anchor boxes\n",
    "priors = generate_ssd_priors(specs, IMAGE_SIZE[0])\n",
    "target_transform = MatchPrior(priors, center_variance, size_variance, iou_threshold)\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SSD & load checkpoint\n",
    "# ----------------------start--------------------------------\n",
    "# build SSD\n",
    "print(\"Building SSD Model with EfficientNet{0} backbone..\".format(MODEL_NAME))\n",
    "model = ssd(MODEL_NAME, pretrained=False)\n",
    "\n",
    "# load checkpoint\n",
    "print(\"Loading Checkpoint..\")\n",
    "if checkpoint_filepath is not None:\n",
    "    print(\"Loading Checkpoint..\", checkpoint_filepath)\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "else:\n",
    "    print(\"Training from with only base model pretrained on imagenet\")\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "# ----------------------start--------------------------------\n",
    "dataset = tf.data.Dataset.list_files(INPUT_DIR + '/*', shuffle=False)\n",
    "filenames = list(dataset.as_numpy_iterator())\n",
    "dataset = dataset.map(prepare_for_prediction)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the image\n",
    "# ----------------------start--------------------------------\n",
    "pred = model.predict(dataset, verbose=1)\n",
    "predictions = post_process(pred, target_transform, confidence_threshold=0.4)\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes of human & save image\n",
    "# ----------------------start--------------------------------\n",
    "print(\"Prediction Complete\")\n",
    "for i, path in enumerate(filenames):\n",
    "    path_string = path.decode(\"utf-8\")\n",
    "    im = imread(path_string)\n",
    "    filename = path_string.split('/')[-1]\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "    ax.imshow(im)\n",
    "    pred_boxes, pred_scores, pred_labels = predictions[i]\n",
    "    if pred_boxes.size > 0:\n",
    "        draw_bboxes(pred_boxes, ax , labels=pred_labels, IMAGE_SIZE=im.shape[:2])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'out_'+ filename), bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "print(\"Output is saved in\", OUTPUT_DIR)\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load python packet   \n",
    "# ----------------------start--------------------------------\n",
    "# load necessary packets\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# load utilities\n",
    "from utils.priors import *\n",
    "from model.ssd import ssd\n",
    "from model.loss import multibox_loss\n",
    "from utils.preprocessing import prepare_dataset\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,  ReduceLROnPlateau, ModelCheckpoint\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters & directory paths\n",
    "# ----------------------start--------------------------------\n",
    "# define directory path of dataset\n",
    "DATASET_DIR = './dataset'\n",
    "# define parameter\n",
    "IMAGE_SIZE = [300, 300]\n",
    "# define parameter\n",
    "BATCH_SIZE = 16\n",
    "# choose backbone net [B0, B1, B2, ..., B7]\n",
    "MODEL_NAME = 'B0'\n",
    "# define number of epochs\n",
    "EPOCHS = 5\n",
    "\n",
    "# directory path of weight of pretrained model [./checkpoints/efficientnetb0_SSD.h5]\n",
    "checkpoint_filepath = ??? \n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data loader\n",
    "# ----------------------start--------------------------------\n",
    "print(\"Loading Data..\")\n",
    "train_data = tfds.load(\"voc\", data_dir=DATASET_DIR, split='train')\n",
    "number_train = train_data.reduce(0, lambda x, _: x + 1).numpy()\n",
    "print(\"Number of Training Files:\", number_train)\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters of SSD\n",
    "# ----------------------start--------------------------------\n",
    "# set positive box's threshold\n",
    "iou_threshold = 0.5\n",
    "# set anchor center's variance\n",
    "center_variance = 0.1\n",
    "# set anchor size's variance\n",
    "size_variance = 0.2\n",
    "\n",
    "# set anchor boxes\n",
    "specs = [\n",
    "                SSDSpec(38, 8, SSDBoxSizes(30, 60), [2]),\n",
    "                SSDSpec(19, 16, SSDBoxSizes(60, 111), [2, 3]),\n",
    "                SSDSpec(10, 32, SSDBoxSizes(111, 162), [2, 3]),\n",
    "                SSDSpec(5, 64, SSDBoxSizes(162, 213), [2, 3]),\n",
    "                SSDSpec(3, 100, SSDBoxSizes(213, 264), [2]),\n",
    "                SSDSpec(1, 300, SSDBoxSizes(264, 315), [2])\n",
    "        ]\n",
    "\n",
    "# create SSD's anchor boxes\n",
    "priors = generate_ssd_priors(specs, IMAGE_SIZE[0])\n",
    "target_transform = MatchPrior(priors, center_variance, size_variance, iou_threshold)\n",
    "# instantiate the datasets\n",
    "training_dataset = prepare_dataset(train_data, IMAGE_SIZE, BATCH_SIZE, target_transform, train=True)\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SSD & calculate number of steps\n",
    "# ----------------------start--------------------------------\n",
    "# build SSD\n",
    "print(\"Building SSD Model with EfficientNet{0} backbone..\".format(MODEL_NAME))\n",
    "model = ssd(MODEL_NAME)\n",
    "# calculate number of steps\n",
    "steps_per_epoch = number_train // BATCH_SIZE\n",
    "print(\"Number of Train Batches:\", steps_per_epoch)\n",
    "# method summarizes detail of model\n",
    "model.summary()\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters of model\n",
    "# ----------------------start--------------------------------\n",
    "# define learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, min_lr=1e-5, verbose=1)\n",
    "# define checkpoint method\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1)\n",
    "# set initial learning rate\n",
    "base_lr = 1e-3 if checkpoint_filepath is None else 1e-5\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compiler\n",
    "# ----------------------start--------------------------------\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=base_lr),\n",
    "    loss = multibox_loss\n",
    ")\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume checkpoint\n",
    "# ----------------------start--------------------------------\n",
    "if checkpoint_filepath is not None:\n",
    "    print(\"Continuing Training from\", checkpoint_filepath)\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "else:\n",
    "    print(\"Training from with only base model pretrained on imagenet\")\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# ----------------------start--------------------------------\n",
    "history = model.fit(training_dataset, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[reduce_lr,checkpoint]) \n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load python packet   \n",
    "# ----------------------start--------------------------------\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from utils.priors import *\n",
    "from model.ssd import ssd\n",
    "from utils.post_processing import post_process\n",
    "from utils.preprocessing import prepare_for_prediction\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "# ----------------------start--------------------------------\n",
    "np.random.seed(42)\n",
    "COLORS = [list(np.random.random(size=3) * 256) for i in range(20)]\n",
    "CLASSES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', \n",
    "           'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', \n",
    "           'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', \n",
    "           'tvmonitor'] \n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "# ----------------------start--------------------------------\n",
    "def parse_opt():\n",
    "    parser = argparse.ArgumentParser(\n",
    "    description='Single Shot MultiBox Detector Training With Keras')\n",
    "    parser.add_argument('-video', default=None,\n",
    "                    help='Directory of video')\n",
    "    parser.add_argument('-delay', type=int, default=1, help='delay per frame in MS')\n",
    "    parser.add_argument('--net', default=\"B0\",\n",
    "                    help=\"The network architecture, it can be B0, B1, B2, ..., B7 \")\n",
    "    parser.add_argument('--checkpoint', default='./checkpoints/efficientnetb0_SSD.h5',\n",
    "                    help='Directory of checkpoint models (./checkpoints/efficientnetb0_SSD.h5)')\n",
    "    return parser.parse_args()\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bboxes\n",
    "# ----------------------start--------------------------------\n",
    "def draw_bboxes(bboxes, frame, labels=None, fill=False, IMAGE_SIZE=[300, 300]):\n",
    "    if np.max(bboxes) < 20:\n",
    "        bboxes[:, [0,2]] = bboxes[:, [0,2]]*IMAGE_SIZE[1]\n",
    "        bboxes[:, [1,3]] = bboxes[:, [1,3]]*IMAGE_SIZE[0]\n",
    "    obj = []\n",
    "    overlay = frame.copy()\n",
    "    alpha = 0.1\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        ind = int(labels[i] - 1)\n",
    "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), \n",
    "                             (int(bbox[2]), int(bbox[3])), COLORS[ind], 2)\n",
    "        if fill:\n",
    "            cv2.rectangle(overlay, (int(bbox[0]), int(bbox[1])), \n",
    "                                (int(bbox[2]), int(bbox[3])), COLORS[ind], -1)\n",
    "        if labels is not None:\n",
    "            cv2.putText(frame, CLASSES[int(labels[i] - 1)], \n",
    "                               (int(bbox[0]+0.5), int(bbox[1]-10)),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                               COLORS[ind], 2)\n",
    "        obj.append([CLASSES[int(labels[i] - 1)],int(bbox[0]), int(bbox[1])])\n",
    "    if fill:\n",
    "        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    return np.asarray(obj), frame\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check argument\n",
    "# ----------------------start--------------------------------\n",
    "opt = parse_opt(args=[])\n",
    "# opt = parse_opt(args=['-video','./images/input.mp4'])\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check type of input\n",
    "# ----------------------start--------------------------------\n",
    "if opt.video:\n",
    "    cap = cv2.VideoCapture(opt.video)\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check whether user selected camera is opened successfully.\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"Welcome to Human detection\")\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "# ----------------------start--------------------------------\n",
    "IMAGE_SIZE = [300, 300]\n",
    "opt.net = opt.net\n",
    "checkpoint_filepath = opt.checkpoint\n",
    "# -------------------------end------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters of SSD\n",
    "# ----------------------start--------------------------------\n",
    "# set positive box's threshold\n",
    "iou_threshold = 0.5\n",
    "# set anchor center's variance\n",
    "center_variance = 0.1\n",
    "# set anchor size's variance\n",
    "size_variance = 0.2\n",
    "\n",
    "# set anchor boxes\n",
    "specs = [\n",
    "                SSDSpec(38, 8, SSDBoxSizes(30, 60), [2]),\n",
    "                SSDSpec(19, 16, SSDBoxSizes(60, 111), [2, 3]),\n",
    "                SSDSpec(10, 32, SSDBoxSizes(111, 162), [2, 3]),\n",
    "                SSDSpec(5, 64, SSDBoxSizes(162, 213), [2, 3]),\n",
    "                SSDSpec(3, 100, SSDBoxSizes(213, 264), [2]),\n",
    "                SSDSpec(1, 300, SSDBoxSizes(264, 315), [2])\n",
    "        ]\n",
    "\n",
    "priors = generate_ssd_priors(specs, IMAGE_SIZE[0])\n",
    "target_transform = MatchPrior(priors, center_variance, size_variance, iou_threshold)\n",
    "# -------------------------end------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build SSD & load weight\n",
    "# ----------------------start--------------------------------\n",
    "# build SSD\n",
    "print(\"Building SSD Model with EfficientNet{0} backbone..\".format(opt.net))\n",
    "model = ssd(opt.net, pretrained=False)\n",
    "# load weight\n",
    "print(\"Loading Checkpoint..\")\n",
    "if checkpoint_filepath is not None:\n",
    "    print(\"Loading Checkpoint..\", checkpoint_filepath)\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "else:\n",
    "    print(\"Training from with only base model pretrained on imagenet\")\n",
    "# method summarizes detail of model\n",
    "model.summary()\n",
    "# -------------------------end-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check argument\n",
    "# ----------------------start--------------------------------\n",
    "opt = parse_opt(args=[])\n",
    "# opt = parse_opt(args=['-video','./images/input.mp4'])\n",
    "# -------------------------end-------------------------------\n",
    "\n",
    "# main\n",
    "# ----------------------start--------------------------------\n",
    "try:\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # convert to Keras tensor\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (300,300))\n",
    "        img = img/255.0\n",
    "        img = np.reshape(img,(1,300,300,3))\n",
    "\n",
    "        # Our operations on the frame come here\n",
    "        pred = model.predict(img, verbose=1)\n",
    "        predictions = post_process(pred, target_transform, confidence_threshold=0.4)\n",
    "\n",
    "        pred_boxes, pred_scores, pred_labels = predictions[0]\n",
    "        if pred_boxes.size > 0:\n",
    "            obj, frame = draw_bboxes(pred_boxes, frame , labels=pred_labels, fill=True, IMAGE_SIZE=(height, width))\n",
    "        \n",
    "            print(obj)\n",
    "            cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(opt.delay) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopped by keyboard interrupt')\n",
    "    cap.release()\n",
    "# -------------------------end-------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
